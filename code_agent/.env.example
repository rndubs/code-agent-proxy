# LiteLLM Configuration
# Base URL for the LiteLLM proxy (running in parent directory)
LITELLM_BASE_URL=http://localhost:4000

# API key for authentication (use LITELLM_MASTER_KEY from parent .env)
LITELLM_API_KEY=sk-1234

# Model to use - Available models from ../litellm_config.yaml:
# OpenAI models: gpt-4, gpt-4-turbo, gpt-3.5-turbo
# Claude models: claude-3-5-sonnet, claude-3-opus, claude-3-sonnet, claude-3-haiku
LITELLM_MODEL=gpt-4

# For best results with tool calling, use:
# LITELLM_MODEL=gpt-4-turbo
# LITELLM_MODEL=claude-3-5-sonnet
